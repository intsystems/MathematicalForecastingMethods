{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByhvD3Vj4MjM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "import scipy.linalg\n",
    "import scipy.signal\n",
    "import operator\n",
    "import sympy\n",
    "import itertools\n",
    "\n",
    "LETTERS = \"ijklmnoprst\"\n",
    "\n",
    "def prod(iterable):\n",
    "  return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "def without(list_, idx):\n",
    "  return list_[:idx] + list_[idx+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi4xPq7RCTtK"
   },
   "source": [
    "В данном ДЗ допускается использование циклов **только** по размерности массивов (и по итерациям, где они есть). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAucswrN7c8p"
   },
   "source": [
    "# 1. Реализация ALS алгоритма для канонического тензорного разложения\n",
    "\n",
    "В этой части задачи мы реализуем ALS алгоритм, который является популярным выбором в приложениях благодаря своей простоте и возможности адаптировать алгоритм к тензорам, имеющим дополнительную структуру (например, разреженность).\n",
    "\n",
    "С помощью ```np.einsum``` напишите функцию, вычисляющую полный тензор $A$ по его каноническому разложению. Пользуйтесь ей при отладке дальнейшего кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32pm7T8FImIg"
   },
   "outputs": [],
   "source": [
    "def full(X):\n",
    "  '''\n",
    "  Input:\n",
    "    X: X = (U1, U2, U3) - tuple of CP factors (numpy arrays)\n",
    "\n",
    "  Output:\n",
    "    A: 3d full tensor, constructed from its CP representation\n",
    "  '''\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jWxFTFpJSgE"
   },
   "outputs": [],
   "source": [
    "U, V, W = np.ones((4, 2)), np.ones((5, 2)), np.ones((6, 2))\n",
    "assert np.linalg.norm(full((U, V, W)) - 2 * np.ones((4, 5, 6))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSy-TiZmVe1W"
   },
   "source": [
    "Напишем теперь несколько вспомогательных функций\n",
    "\n",
    "Используя ```np.einsum``` напишите функцию ```mttkrp``` (Matricized tensor times Khatri-Rao product), вычисляющую \n",
    "$$\n",
    "  A_{(p)} (U^{(d)} \\odot \\dots \\odot U^{(p+1)} \\odot U^{(p-1)} \\odot \\dots \\odot U^{(1)})\n",
    "$$\n",
    "для $d=3$ и $p=1,2,3$. Используйте ```np.einsum``` только один раз, заранее подготовив строку для правила суммирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOsj7c8Zcw1V"
   },
   "outputs": [],
   "source": [
    "def mttkrp(A, X, p):\n",
    "  '''\n",
    "  Input:\n",
    "    A: 3D tensor\n",
    "    X: a tuple of 2 numpy arrays: (U1, U2, U3), excluding the p-th matrix\n",
    "    p: 0, 1 or 2\n",
    "\n",
    "  Output:\n",
    "    Up: 2D numpy array\n",
    "  '''\n",
    "  \n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyKcPqzmA3dU"
   },
   "outputs": [],
   "source": [
    "U, V, W = np.ones((4, 2)), np.ones((5, 2)), np.ones((6, 2))\n",
    "A = np.ones((4, 5, 6))\n",
    "\n",
    "assert np.linalg.norm(mttkrp(A, (V, W), 0) - 5*6*U) == 0\n",
    "assert np.linalg.norm(mttkrp(A, (U, W), 1) - 4*6*V) == 0\n",
    "assert np.linalg.norm(mttkrp(A, (U, V), 2) - 4*5*W) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmDD5eYULqup"
   },
   "source": [
    "Используя Фробениусово скалярное произведение напишите функцию для вычисления ошибки $\\|A - [[U^{(1)}, U^{(2)}, U^{(3)}]]\\|_F$, считая, что $\\|A\\|_F$ и $M = A_{(3)} (U^{(2)} \\odot U^{(1)})$ заданы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp245tbpmMvh"
   },
   "outputs": [],
   "source": [
    "def err_nrm(nrm_A, M, X):\n",
    "  '''\n",
    "  Input:\n",
    "    nrm_A: Frobenius norm of A. \n",
    "    M: mttkrp with A and matrices U1, U2\n",
    "    X: a tuple of 3 numpy arrays: (U1, U2, U3)\n",
    "\n",
    "  Output:\n",
    "    err: Frobenius norm of the error\n",
    "  '''\n",
    "  \n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAO58Wk1PsWP"
   },
   "outputs": [],
   "source": [
    "U = np.random.randn(10, 3)\n",
    "V = np.random.randn(10, 3)\n",
    "W = np.random.randn(10, 3)\n",
    "\n",
    "A = np.random.random((10, 10, 10))\n",
    "M = mttkrp(A, (U, V), 2)\n",
    "nrm_A = np.linalg.norm(A)\n",
    "\n",
    "assert abs(err_nrm(nrm_A, M, (U, V, W)) - np.linalg.norm(A - full((U, V, W)))) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ALS алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13dmMSF7HBVV"
   },
   "source": [
    " Реализуйте функцию для ALS алгоритма, вычисляющую приближение заданного ранга к тензору $A$. После каждой внутренней итерации нормируйте столбцы соответствующей матрицы $U^{(k)}$. Также на выходе функции необходимо предоставить два списка из ошибок на каждой итерации: с ошибками\n",
    "$$\n",
    "\\mathtt{err\\_1} = \\left\\|A - [[U_k,V_k,W_k]]\\right\\|_F/\\|A\\|_F\n",
    "$$ (необходимо вычислять перед последней нормализацией) и \n",
    "$$\n",
    "\\mathtt{err\\_2} = \\frac{\\sqrt{\\|U_k - U_{k-1}\\|_F^2 + \\|V_k - V_{k-1}\\|_F^2 + \\|W_k - W_{k-1}\\|_F^2}}{\\sqrt{\\|U_k\\|_F^2 + \\|V_k\\|_F^2 + \\|W_k \\|_F^2}}.\n",
    "$$\n",
    "При написании функции используйте реализованные выше функции ```mttkrp``` и ```err_nrm```.\n",
    "\n",
    "Заметьте, на выход функции один из факторов нужно подать ненормализованным (подобно тому, как вычисляется `err_1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VB2WnzhFbozi"
   },
   "outputs": [],
   "source": [
    "def als_multilinear(A, rank, tol, X0, maxiter=1000):\n",
    "  '''\n",
    "  Input:\n",
    "    A: 3D numpy array \n",
    "    rank: approximation rank\n",
    "    tol: stopping tolerance level for err_2\n",
    "    X0: initial guess (U0, V0, W0) for the iterative process\n",
    "    maxiter: maximum number of iterations\n",
    "\n",
    "  Output:\n",
    "    X: tuple (U, V, W) - CP factors of the approximation\n",
    "    errs_1: list of errors err_1\n",
    "    errs_2: list of errors err_2\n",
    "  '''\n",
    "\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxBA5W9R1rr-"
   },
   "source": [
    "Запустим полученный алгоритм на тензоре, возникаюшем при перемножении $2\\times 2$ матриц. Запустите метод при значениях ```seed```, равных $0, 1$ и $3$. Прокомментируйте поведения сходимости в этих случаях.\n",
    "\n",
    "Сравните полученные результаты ```tensorly.decomposition.parafac```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0o8rO43x4wxI"
   },
   "outputs": [],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed) #3 4\n",
    "\n",
    "A = np.zeros((4, 4, 4))\n",
    "A[:, :, 0] = [[1, 0, 0, 0],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 0, 0, 0]]\n",
    "A[:, :, 1] = [[0, 0, 0, 0],\n",
    "              [1, 0, 0, 0],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 1, 0, 0]]\n",
    "A[:, :, 2] = [[0, 0, 1, 0],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 0, 0, 1],\n",
    "              [0, 0, 0, 0]]\n",
    "A[:, :, 3] = [[0, 0, 0, 0],\n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 0, 0, 1]]\n",
    "rank = 7\n",
    "\n",
    "sz = A.shape\n",
    "U0 = np.random.randn(sz[0], rank)\n",
    "V0 = np.random.randn(sz[1], rank)\n",
    "W0 = np.random.randn(sz[2], rank)\n",
    "\n",
    "X, errs_1, errs_2 = als_multilinear(A, rank, 1e-14, (U0, V0, W0), maxiter=600)\n",
    "\n",
    "plt.semilogy(errs_1, label='errs_1')\n",
    "plt.semilogy(errs_2, label='errs_2')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ErD8Qq9g1ly"
   },
   "source": [
    "# 2. Применение CP разложения для обработки данных электроэнцефалограммы (ЭЭГ)\n",
    "\n",
    "В этой задаче мы запустим алгоритм на открытых [данных ЭЭГ](http://archive.ics.uci.edu/ml/datasets/EEG+Database), использующихся для изучения особенностей ЭЭГ при алкогольной зависимости. Датасет включает в себя измерения энцефалограммы на частоте 256 Гц с 64 электродов (число каналов), расположенных на голове 119 пациентов (76 с алкогольной зависимостью и 43 контрольных пациента) и записанные в течение 1 секунды после показа некоторого изображения. Данные обработаны и приведены к виду тензора с помощью открытого [кода](https://github.com/kharyuk/vbtd) из [статьи](https://link.springer.com/article/10.1134/S0965542521050146) и находятся в файле ```smni_eeg.npz```. Произведем их выгрузку. [Ссылка на данные](https://yadi.sk/d/LVf_R3MK0j7pAA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99u1MbsBh7op"
   },
   "outputs": [],
   "source": [
    "processed_filename = 'smni_eeg_processed.npz'\n",
    "df = np.load(processed_filename)\n",
    "data, labels = df['data'], df['labels']\n",
    "\n",
    "Nsubjects, Nchannels, Ntime, Nconditions = data.shape\n",
    "\n",
    "# For simplicity we will only use 1 condition out of 3 and take every second electrode\n",
    "data = data[:, ::2, :, 0]\n",
    "\n",
    "sample_frequency = 256 # Hz\n",
    "timepoints = 1000.0 * np.arange(Ntime) / sample_frequency # ms\n",
    "\n",
    "ind_alcohol = list(np.where(labels == 0)[0])[:10] #[:10] is to make tensor smaller\n",
    "ind_control = list(np.where(labels == 1)[0])[:10] #[:10] is to make tensor smaller\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 4))\n",
    "\n",
    "ax[0].plot(timepoints, data[ind_alcohol[2], 4, :].T, color='k');\n",
    "ax[1].plot(timepoints, data[ind_control[2], 4, :].T, color='k');\n",
    "\n",
    "ax[1].set_xlabel('time, ms');\n",
    "ax[0].set_ylabel('voltage, mV');\n",
    "ax[1].set_ylabel('voltage, mV');\n",
    "ax[0].set_title('EEG signals on one of the electrodes (addicted to alcohol)');\n",
    "ax[1].set_title('EEG signals on one of the electrodes (control)');\n",
    "ax[0].set_ylim([-10, 10])\n",
    "ax[1].set_ylim([-10, 10])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ZVeb6f2SHq"
   },
   "source": [
    "Теперь подготовим данные. Для этого по временной координате возьмем оконное преобразование Фурье (short-time Fourier transform, STFT). STFT соответствует разбиению временного интервала на несколько пересекающихся сегментов и применению к каждому из них преобразования Фурье, что позволяет улавливать изменение частоты сигнала от времени. В итоге мода размера Ntime ращепится на 2 составляющие: число сегментов и частота в каждом из сегментов. Для избежания комплесных чисел и упрощения модели мы рассмотрим абсолютные значения тензора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJNI4RNc2Ld9"
   },
   "outputs": [],
   "source": [
    "axis = -1 # timepoints\n",
    "sample_rate = 256 # 256 Hz\n",
    "nperseg = 256 # number of points per segment\n",
    "\n",
    "f, t, A = scipy.signal.stft(data, fs=sample_rate, window='hann', \n",
    "                            nperseg=nperseg, noverlap=None, nfft=None, \n",
    "                            detrend=False, return_onesided=True, \n",
    "                            boundary='zeros', padded=True, axis=axis)\n",
    "\n",
    "A = np.abs(A)\n",
    "\n",
    "sz = A[0, :, :, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6JFgZOAsNHm"
   },
   "source": [
    "Напишем функцию ```normalize```, эквивалентно представляющую тензор $A = [[U, V, W]]$ в виде:\n",
    "$$\n",
    "  A = \\sum_{\\alpha=1}^R s_\\alpha\\, u_\\alpha \\circ v_\\alpha \\circ w_\\alpha, \\quad \\|u_\\alpha\\|_2 = \\|v_\\alpha\\|_2 = \\|w_\\alpha\\|_2 = 1\n",
    "$$\n",
    "с отсортированными по убыванию значениями $s_\\alpha$. Далее мы будем анализировать значения $s_\\alpha$ -- величина вклада соответствующей компоненты ранга 1 в итоговую сумму.\n",
    "\n",
    "Напишите функцию ```normalize```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYFnKTQJsMAO"
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "  '''\n",
    "    Input:\n",
    "        X: (U, V, W) tuple\n",
    "    \n",
    "    Output:\n",
    "        s: array, containing norms of rank-1 terms in the descending order\n",
    "        (U, V, W): tuple with the respective canonical factors\n",
    "  '''\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SKFbzou01O0"
   },
   "source": [
    "Запустим ALS метод для одного из пациентов для разных значений рангов (и для ускорения вычислений взяв в 2 раза меньше электродов). Объясните наблюдаемое поведение сходимости для все значений рангов. Предложите, что нужно изменить в коде для ALS, чтобы избежать наблюдаемых проблем со сходимостью при некоторых значениях рангов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5x6qZ8U4iqe"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "for rank in range(8, 60, 5):\n",
    "  U0 = np.random.randn(sz[0]//2, rank)\n",
    "  V0 = np.random.randn(sz[1], rank)\n",
    "  W0 = np.random.randn(sz[2], rank)\n",
    "  \n",
    "  X, errs_1, errs_2 = als_multilinear(A[0, ::2, :, :], rank, 1e-6, (U0, V0, W0), maxiter=20)\n",
    "\n",
    "  plt.semilogy(errs_1, label=rank)\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xikCv8k57f3B"
   },
   "source": [
    "### Классификация\n",
    "\n",
    "В качестве признаков для отличия двух классов попробуем использовать простейший вариант – $s_\\alpha$ (вклады от компонент ранга 1). Интуитивно кажется, что можно ожидать пониженную активизацию центров активности мозга у людей с положительным диагнозом. Попробуем увидеть эту закономерности для некоторых из значений рангов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iM0xNsFQt_rz"
   },
   "outputs": [],
   "source": [
    "ranks = [2, 5, 10, 20, 40, 60]\n",
    "\n",
    "fig, ax = plt.subplots(len(ranks), 1, figsize=(10, 3*len(ranks)))\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for j, rank in enumerate(ranks):\n",
    "\n",
    "  U0 = np.random.randn(sz[0], rank)\n",
    "  V0 = np.random.randn(sz[1], rank)\n",
    "  W0 = np.random.randn(sz[2], rank)\n",
    "\n",
    "  s_alc = np.zeros((rank, len(ind_alcohol)))\n",
    "  s_ctrl = np.zeros((rank, len(ind_control)))\n",
    "\n",
    "  j_alc = 0\n",
    "  j_ctrl = 0\n",
    "  for i in ind_alcohol + ind_control:\n",
    "    B = A[i, :, :, :]\n",
    "    X, errs_1, errs_2 = als_trilinear(B, rank, 1e-6, (U0, V0, W0), maxiter=100)\n",
    "    s, X = normalize(X)\n",
    "\n",
    "    if i in ind_alcohol:\n",
    "      s_alc[:, j_alc] = s\n",
    "      j_alc += 1\n",
    "    else:\n",
    "      s_ctrl[:, j_ctrl] = s\n",
    "      j_ctrl += 1\n",
    "\n",
    "  mean_alc = np.mean(s_alc, axis=-1)\n",
    "  std_alc = np.std(s_alc, axis=-1)\n",
    "  ax[j].plot(mean_alc, label='alc')\n",
    "  ax[j].fill_between(range(len(mean_alc)), mean_alc-std_alc, mean_alc+std_alc, alpha=.1)\n",
    "\n",
    "  mean_ctrl = np.mean(s_ctrl, axis=-1)\n",
    "  std_ctrl = np.std(s_ctrl, axis=-1)\n",
    "  ax[j].plot(mean_ctrl, label='control')\n",
    "  ax[j].fill_between(range(len(mean_ctrl)), mean_ctrl-std_ctrl, mean_ctrl+std_ctrl, alpha=.1)\n",
    "    \n",
    "  ax[j].set_title('rank = {}'.format(rank))\n",
    "\n",
    "  ax[j].legend()\n",
    "  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRLFWVFz7qek"
   },
   "source": [
    "На практике, конечно, необходимо использовать более серьезные подходы, включающие дополнительные ограничения на факторы разложения, например, неотрицательность факторов, статистическую независимость компонент и т.д., а также анализировать значения в самих факторах. Подробнее с этим приложением можно ознакомиться, например, в статье [Tensor decomposition of EEG signals: A brief review, F. Cong et al., 2015](https://www.sciencedirect.com/science/article/pii/S0165027015001016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfB0r28f4sWV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
